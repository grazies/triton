{
  "name": "Triton",
  "tagline": "Joyent Triton DataCenter: a cloud management platform with first class support for containers.",
  "body": "<!--\r\n    This Source Code Form is subject to the terms of the Mozilla Public\r\n    License, v. 2.0. If a copy of the MPL was not distributed with this\r\n    file, You can obtain one at http://mozilla.org/MPL/2.0/.\r\n-->\r\n\r\n<!--\r\n    Copyright (c) 2016, Joyent, Inc.\r\n-->\r\n\r\n\r\n# Triton DataCenter\r\n\r\nTriton DataCenter (just \"Triton\" for short, formerly \"SmartDataCenter\" and\r\n\"SDC\") is an open-source cloud management platform that delivers next\r\ngeneration, container-based, service-oriented infrastructure across one or more\r\ndata centers. With an emphasis on ease of installation and operation, Triton is\r\nproven at scale: Triton powers the [Triton\r\nCloud](https://www.joyent.com/datacenter/docs/cloud) and private data centers\r\n([Triton Enterprise]( https://www.joyent.com/datacenter/docs/enterprise)\r\nworldwide.\r\n\r\nThis repository provides documentation for the overall Triton project and\r\npointers to the other repositories that make up a complete Triton deployment.\r\nSee the [repository list](./docs/developer-guide/repos.md).\r\n\r\nReport bugs and request features using [GitHub Issues](https://github.com/joyent/triton/issues).\r\nFor additional resources, you can visit the\r\n[Joyent Developer Center](https://www.joyent.com/developers).\r\n\r\n\r\n## Overview\r\n\r\nA Triton DataCenter installation consists of two or more servers. All servers run\r\n[SmartOS](http://smartos.org). One server acts as the management server, the\r\nheadnode, which houses the initial set of core services that drive Triton. The\r\nremainder are compute nodes (CNs) which run instances (containers and\r\nvirtual machines).\r\n\r\nTriton features:\r\n\r\n- SmartOS zones provides high performance container virtualization. KVM support\r\n  on top of zones means secure full Linux and Windows guest OS support.\r\n- RESTful API and CLI tooling for customer self-service\r\n- Complete operator portal (web app)\r\n- Robust and observable service oriented architecture (implemented primarily in\r\n  Node.js)\r\n- Automated USB key installation\r\n\r\nTriton consists of the following components:\r\n\r\n- A public API for provisioning and managing instances (virtual machines),\r\n  networks, users, images, etc.\r\n- An operator portal\r\n- A set of private APIs\r\n- Agents running in the global zone of CNs for management and monitoring\r\n\r\nFor more details, see:\r\n\r\n- The [Triton Enterprise](https://docs.joyent.com/private-cloud) documentation.\r\n- [Triton DataCenter Architecture](./docs/developer-guide/architecture.md) for\r\n  overall architecture.\r\n- [Triton DataCenter Reference](./docs/reference.md) for an\r\n  overview of each component.\r\n\r\n\r\n## Community\r\n\r\nCommunity discussion about Triton DataCenter happens in two main places:\r\n\r\n* The *sdc-discuss* mailing list. Once you [subscribe to the list](https://www.listbox.com/subscribe/?list_id=247449),\r\n  you can send mail to the list address: sdc-discuss@lists.smartdatacenter.org.\r\n  The mailing list archives are also [available on the web](https://www.listbox.com/member/archive/247449/=now).\r\n\r\n* In the *#smartos* IRC channel on the [Freenode IRC network](https://freenode.net/).\r\n\r\nYou can also follow [@SmartDataCenter](https://twitter.com/SmartDataCenter) on\r\nTwitter for updates.\r\n\r\n\r\n## Getting Started\r\n\r\n### Cloud on a Laptop (CoaL)\r\n\r\nAn easy way to try Triton DataCenter is by downloading a Cloud on a Laptop\r\n(CoaL) build. This is a VMware virtual appliance providing a\r\nfull Triton headnode for development and testing.\r\n\r\nThe minimum requirements, practically speaking, for a good CoaL experience\r\nis a **Mac with at least 16 GB RAM and an SSD**. Currently, almost all team\r\nmembers using CoaL are on Macs with VMware Fusion. Vmware Workstation for\r\nLinux is used by a few in the community. VMware Workstation for Windows\r\nshould work, but has not recently been tested.\r\n\r\nSee [CoaL Setup](./docs/developer-guide/coal-setup.md) for a thorough\r\nwalkthrough including updating CoaL and enabling provisioning on the\r\nheadnode.\r\n\r\n1. Start the download of the latest CoaL build. The tarball is\r\n   approximately 2 GB.\r\n\r\n    ```bash\r\n    curl -C - -O https://us-east.manta.joyent.com/Joyent_Dev/public/SmartDataCenter/coal-latest.tgz\r\n    ```\r\n\r\n2. Install VMware, if you haven't already.\r\n    - Mac: [VMware Fusion](http://www.vmware.com/products/fusion) 5, 7, or 8.\r\n    - Windows or Linux: [VMware Workstation](http://www.vmware.com/products/workstation).\r\n\r\n3. Configure VMware virtual networks for CoaL's \"external\" and \"admin\"\r\n   networks. This is a one time configuration for a VMware installation.\r\n\r\n    1. Launch VMware at least once after installing VMware.\r\n\r\n    2. Run Triton set up script for VMware:\r\n\r\n         - Mac:\r\n\r\n            ```bash\r\n            curl -s https://raw.githubusercontent.com/joyent/triton/master/tools/coal-mac-vmware-setup | sudo bash\r\n            ```\r\n\r\n         - Linux:\r\n\r\n            ```bash\r\n            curl -s https://raw.githubusercontent.com/joyent/triton/master/tools/coal-linux-vmware-setup | sudo bash\r\n            ```\r\n\r\n         - Windows:\r\n\r\n            ```\r\n            Download https://raw.githubusercontent.com/joyent/triton/master/tools/coal-windows-vmware-setup.bat\r\n            Run coal-windows-vmware-setup.bat\r\n            ```\r\n\r\n4. Unpack the CoaL build that you downloaded in step 1.\r\n\r\n    - Mac:\r\n\r\n        ```bash\r\n        $ tar -zxvf coal-latest.tgz\r\n        x root.password.20140911t161518z\r\n        x coal-master-20140911T194415Z-g1a445f5-4gb.vmwarevm/\r\n        x coal-master-20140911T194415Z-g1a445f5-4gb.vmwarevm/USB-headnode.vmx\r\n        x coal-master-20140911T194415Z-g1a445f5-4gb.vmwarevm/zpool.vmdk\r\n        x coal-master-20140911T194415Z-g1a445f5-4gb.vmwarevm/USB-headnode.vmdk\r\n        x coal-master-20140911T194415Z-g1a445f5-4gb.vmwarevm/4gb.img\r\n        ...\r\n        ```\r\n\r\n5. Start VMware and load the appliance.\r\n\r\n    - Mac: 'open'ing the folder will start VMware and \"open and run\" the vm:\r\n\r\n            open coal-<branch>-<build_date_time>-<git_sha1_hash>-4gb.vmwarevm\r\n\r\n6. Boot the headnode.\r\n\r\n  When you are prompted with the GRUB menu press the \"down\" arrow.\r\n\r\n  1. Press the down arrow key to highlight \"Live 64-bit\".\r\n\r\n  1. Press 'c' to go to the command line for GRUB.\r\n\r\n     By default, the OS will redirect the console to ttyb which is fine\r\n     for production but needs to be changed for CoaL. While in the command line:\r\n\r\n            grub> variable os_console vga\r\n\r\n  1. Press enter.\r\n\r\n  1. Press esc to get back to the GRUB menu.\r\n\r\n  1. Boot \"Live 64-bit\" by pressing enter.\r\n\r\n7. Configure the headnode.\r\n\r\nUse the following table to configure your CoaL with settings that\r\nare fine for development.\r\n\r\nIf you make a mistake while entering the configuration you can restart\r\nthe VMware virtual machine. Also, as the onscreen instructions describe,\r\nthe last step in configuration allows editing the resulting configuration file.\r\n\r\n|Setting|Value|Notes|\r\n|---|---|---|\r\n|*Instructions*|↵||\r\n|Company Name|Clavius|*Can substitute with your choice.*|\r\n|Region of Datacenter|orbit|*Can substitute with your choice.*|\r\n|Name of Datacenter|coal-1|(Availability zone.) *Can substitute with your choice.* |\r\n|Location of DataCenter|Moon, Earth|*Can substitute with your choice.*|\r\n|*Instructions*|↵||\r\n|'admin' interface|2|The second NIC is set up as the admin network by the CoaL networking script|\r\n|(admin) headnode IP address|10.99.99.7|Must use this value.|\r\n|(admin) headnode netmask:|↵|Use the default.|\r\n|(admin) Zone's starting IP address:|↵|Use the default.|\r\n|Add external network now? (Y/n)|Y|Must use this value.|\r\n|'external' interface|1|The first NIC is set up as the external network by the CoaL networking script|\r\n|(external) headnode IP address|10.88.88.200|Must use this value.|\r\n|(external) headnode netmask:|↵|Use the default.|\r\n|(external) gateway IP address:|10.88.88.2|Must use this value.|\r\n|(external) network VLAN ID|↵|Use default. The external network is not on a VLAN in CoaL|\r\n|Starting Provisionable IP address for external Network|↵|Use the default.|\r\n|Ending Provisionable IP address for external Network|↵|Use the default.|\r\n|Default gateway IP address:|↵|Use the default.|\r\n|Primary DNS Server|↵|Use the default.|\r\n|Secondary DNS Server|↵|Use the default.|\r\n|Head node domain name|example.com|*Can substitute with your choice.*|\r\n|DNS Search Domain|example.com|*Can substitute with your choice.*|\r\n|NTP Server IP Address|↵|Use the default.|\r\n|\"root\" password|rootpass|*Can substitute with your choice.*|\r\n|Confirm \"root\" password|||\r\n|\"admin\" password|adminpass1|*Can substitute with your choice.*|\r\n|Confirm \"admin\" password|||\r\n|Administrator's email|↵|Use the default.|\r\n|Support email|↵|Use the default.|\r\n|Confirm password|||\r\n|Enable telemetry|\"true\" or \"false\"|*Can use your choice*|\r\n|Verify Configuration|||\r\n|Verify Configuration Again|||\r\n\r\n- CoaL will now install based on the configuration parameters entered\r\n  above. Installation has been observed to take up to 20 minutes,\r\n  particularly if slow laptop HDD.\r\n\r\nAfter setup is complete you should be able to SSH into your CoaL on the\r\n\"admin\" network. Example:\r\n\r\n```bash\r\nssh root@10.99.99.7  # password 'rootpass'\r\n```\r\n\r\nFor just a taste run `svcs` to see running [SMF\r\nservices](http://wiki.smartos.org/display/DOC/Using+the+Service+Management+Facility).\r\nRun `vmadm list` to see a list of current VMs (SmartOS\r\n[zones](http://wiki.smartos.org/display/DOC/Zones)). Each Triton service runs in\r\nits own zone. See [the Joyent customer documentation](https://docs.joyent.com/private-cloud).\r\n\r\nAs mentioned previously, see [CoaL Setup](./docs/developer-guide/coal-setup.md)\r\nfor a thorough walkthrough.\r\n\r\n\r\n### Installing Triton on a Physical Server\r\n\r\nA Triton DataCenter server runs SmartOS which is a live image. This means that\r\nit boots from a USB flash drive (key).\r\na physical USB key, inserting the key and booting the server from that key.\r\nTo install Triton, first obtain the latest release USB build.\r\n\r\n\r\n#### Hardware\r\n\r\nFor Triton development only, the minimum server hardware is:\r\n\r\n- 8 GB USB flash drive\r\n- Intel Processors with VT-x and EPT support (all Xeon since Nehalem)\r\n- 16 GB RAM\r\n- 6 GB available storage\r\n\r\nHardware RAID is not recommended. Triton will lay down a ZFS ZPOOL across all\r\navailable disks on install. You'll want much more storage if you're working with\r\nimages and instances.\r\n\r\nIf setting up a Triton DataCenter pilot then you'll want to review\r\nthe [Minimum Requirements](https://docs.joyent.com/private-cloud/install/site-and-network-requirements)\r\nand [Installation Prerequisites](https://docs.joyent.com/private-cloud/install/deployment-planning)\r\nwhich include IPMI and at least 10 gigabit Ethernet. The supported hardware\r\ncomponents for SmartOS are described in the [SmartOS Hardware Requirements](http://wiki.smartos.org/display/DOC/Hardware+Requirements).\r\nJoyent certified hardware for Triton DataCenter are all in\r\nthe [Joyent Manufacturing Database](https://docs.joyent.com/private-cloud/hardware).\r\n\r\n\r\n#### Install\r\n\r\nTo install Triton, first download the latest release image:\r\n\r\n```bash\r\ncurl -C - -O https://us-east.manta.joyent.com/Joyent_Dev/public/SmartDataCenter/usb-latest.tgz\r\n```\r\n\r\nOnce you have downloaded the latest release image, you will need to\r\n[write it to a USB key](https://docs.joyent.com/private-cloud/install/installation-media)\r\nboot the headnode server using the USB key, and follow the install prompts. All steps necessary\r\nto plan, install, and configure Triton DataCenter (Triton) are available in the Joyent\r\ncustomer documenation [Installing Triton Elastic Container Infrastructure](https://docs.joyent.com/private-cloud/install).\r\n\r\n\r\n## Building\r\n\r\nTriton is composed of several pre-built components:\r\n\r\n- A [SmartOS *platform* image](https://github.com/joyent/smartos-live). This is\r\n  a slightly customized build of vanilla SmartOS for Triton.\r\n- *Virtual machine images* for Triton services (e.g. imgapi, vmapi, adminui), which\r\n  are provisioned as VMs at install time.\r\n- Agents bundled into a [single\r\n  package](https://github.com/joyent/sdc-agents-installer)\r\n  installed into the global zone of each compute node.\r\n\r\nEach component is built separately and then all are combined into CoaL and USB\r\nbuilds (see the preceding sections) via the [sdc-headnode\r\nrepository](https://github.com/joyent/sdc-headnode). The built components are\r\ntypically stored in a [Manta object store](https://github.com/joyent/manta),\r\ne.g. [Joyent's public Manta](https://www.joyent.com/products/manta),\r\nand pulled from there. For example, Joyent's builds push to\r\n`/Joyent_Dev/public/builds` in Joyent's public Manta in us-east-1\r\n(<https://us-east.manta.joyent.com/>).\r\n\r\nYou can build your own CoaL and USB images on Mac or SmartOS (see the\r\n[sdc-headnode README](https://github.com/joyent/sdc-headnode#readme)). However,\r\nall other Triton components must be built using a running Triton\r\n(e.g. on the [Joyent Cloud](https://www.joyent.com/products/compute-service)\r\nor in a local CoaL). See [the building document](./docs/developer-guide/building.md)\r\nfor details on building each of the Triton components.\r\n\r\n\r\n## Contributing\r\n\r\nTo report bugs or request features, submit issues here on\r\nGitHub, [joyent/triton/issues](https://github.com/joyent/triton/issues)\r\n(or on the GitHub issue tracker for the relevant project).\r\nFor support of Joyent products and services, please contact [Joyent customer\r\nsupport](https://help.joyent.com/home) instead.\r\n\r\nSee the [Contribution Guidelines](CONTRIBUTING.md) for information about\r\ncontributing changes to the project.\r\n\r\n\r\n## Design Principles\r\n\r\nTriton DataCenter is very opinionated about how to architect a cloud. These\r\nopinions are the result of many years of deploying and debugging\r\nthe [Joyent public cloud](https://www.joyent.com/public-cloud).\r\nDesign principles include the following:\r\n\r\n- A VM's primary storage should be local disk, not over the network -- this\r\n  avoids difficult to debug performance pathologies.\r\n- Communication between internal APIs should occur in its own control plane\r\n  (network) that is separate from the customer networks. Avoid communicating\r\n  over the open Internet if possible.\r\n- A provisioned VM should rely as little as possible on Triton services outside of\r\n  the operating system for its normal operation.\r\n- Installation and operation should require as little human intervention as\r\n  possible.\r\n\r\nThe goals behind the design of Triton services include:\r\n\r\n- All parts of the stack should be observable.\r\n- The state of the running service should be simple to obtain.\r\n- The internals of the system should make it straightfoward to debug from a\r\n  core file (from a crash or taken from a running process using\r\n  [gcore(1)](http://smartos.org/man/1/gcore)).\r\n- Services should be RESTful and accept JSON unless there is a compelling\r\n  reason otherwise.\r\n- Services should avoid keeping state and should not assume that there is\r\n  only one instance of that service running. This allows multiple instances\r\n  of a service to be provisioned for high availability.\r\n- Node.js and C should be used for new services.\r\n\r\n\r\n## Dependencies and Related Projects\r\n\r\nTriton DataCenter uses [SmartOS](http://smartos.org) as the host operating\r\nsystem. The SmartOS hypervisor provides both SmartOS zone (container) and\r\nKVM virtualization.\r\n\r\nJoyent's open-source [Manta project](https://github.com/joyent/manta)\r\nis an HTTP-based object store with built-in support to run arbitrary\r\nprograms on data at rest (i.e., without copying data out of the object store).\r\nManta runs on and integrates with Triton DataCenter.\r\n\r\n\r\n## License\r\n\r\nTriton DataCenter is licensed under the\r\n[Mozilla Public License version 2.0](http://mozilla.org/MPL/2.0/).\r\nSee the file LICENSE. SmartOS is [licensed separately](http://smartos.org/cddl/).\r\n",
  "note": "Don't delete this file! It's used internally to help with page regeneration."
}